{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Blue\"><font size=\"6\">Stochastic Diffusion Search</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p ><font size=\"4\">An approach to solve the Curse of Dimensionality in Data Science using SDS Feature Selection</font></p> \n",
    "\n",
    "<p ><font size=\"3\">This is a project done for the Optimization course of The Informatics Department at AUTh.</font></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p ><font size=\"3\"> The theory behind the algorithm is originally published <a href=\"https://dl.acm.org/citation.cfm?id=3079193\">here</a>.</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pprint import pprint\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg=LogisticRegression(C=2)\n",
    "decClf=DecisionTreeClassifier(max_depth=5, min_samples_split=4)\n",
    "rfc=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[rfc,logReg,decClf] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "## 1) Initialization Phase - Hypothesis Selection \n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to randomly select an agents hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Below function returns an agent, which is hypothesis, and its corresponding binary array.\n",
    "1 indicates inclusion of corresponding feature and 0 indicates exclusion of the feature.\n",
    "lowerLim indicates minimum number of features, whereas; upperLim indicated max no of features to beincluded in an agent.\n",
    "'''\n",
    "def agent(arryX,lowerLim,upperLim):\n",
    "        if lowerLim<0 or upperLim>arryX.shape[1]:\n",
    "            print('recall function with appropriate limits')\n",
    "        else:\n",
    "            randomNoFeatures=np.random.randint(lowerLim,upperLim,size=1)[0] #generating a random number\n",
    "            zeroArry=np.zeros(arryX.shape[1]-randomNoFeatures, dtype='int') #zero array \n",
    "            oneArry=np.ones(randomNoFeatures, dtype='int')   #one array\n",
    "            fArry=np.concatenate((zeroArry,oneArry), axis=0) #concatinating zero and one array\n",
    "            np.random.shuffle(fArry) #shuffling fArray\n",
    "            fIndex=np.where(fArry==1)[0]\n",
    "            agentArry=arryX[:,fIndex] #generating feature subset from origanal dataset\n",
    "            return fArry,agentArry #returns array of 0s and 1s of features selected, and the new agent's dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to initialize all agents' hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Below function generates required number of agents that are to be deployed on search space. \n",
    "All the agents and corresponding binary feature array are stored and returned as a list.\n",
    "'''\n",
    "def agentsInitiation(arryX,numAgents,lowerLim,upperLim):\n",
    "        agents=[]\n",
    "        agentFIndex=[]\n",
    "        agentStatus=['active']*numAgents #create a status list of 'active' agents\n",
    "        for i in range(0,numAgents):\n",
    "            fArry,agentArry=agent(arryX,lowerLim,upperLim) #generating a single agent\n",
    "            agentFIndex.append(fArry) #appending its binary feature array to agentFIndex (list to store each agent's 0-1 array)\n",
    "            agents.append(agentArry) #appending the agent to the agents list (list to store each agent's dataset)\n",
    "        return agents,agentFIndex,agentStatus #return the 2 lists above, and a list of 'active' statuses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate the score of an agent's hypothesis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red\"><font size=\"2\">TODO: Create actual ensemble - This is just averaging scores</font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "'Score' function fits each model to the agent's training data and then evaluates the score on test data. \n",
    "The output is the average score of three estimators. We calculate the average so we can have an ensemble of model predictions,\n",
    "and thus not be biased toward one specific model's predictions.\n",
    "'''\n",
    "def score(estimators,arryX,arrY):\n",
    "        X_train,X_test,y_train,y_test=train_test_split(arryX,arrY,random_state=0)\n",
    "        scores=[]\n",
    "        for i in range(len(estimators)):\n",
    "            estimators[i].fit(X_train,y_train) #fitting the ith estimator to the training data of an agent\n",
    "            scores.append(estimators[i].score(X_test,y_test)) #evaluating the score on the test data\n",
    "        return sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate the score of all agents and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below function calculates score for each agents and appends the score to the agentScores list\n",
    "def agentClfscores(estimators,agents,arrY):\n",
    "    agentScores=[]\n",
    "    for agent in agents:\n",
    "        agentscore=score(estimators,agent,arrY)\n",
    "        agentScores.append(agentScores)\n",
    "    return agentScores #returns a list that captures agents' scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "## 2) Testing Phase - Turn agents into active ones or inactive ones based on partial evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Diffusion Phase - Information diffusion between agents\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that carries out the testing and diffusion phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Below function carries out test and diffusion phase among the agents initialized above. \n",
    "The function returns agents and their corresponding scores, binary feature arrays, and staus after numIterations.\n",
    "'''\n",
    "\n",
    "def SDSFS(arryX,arrY,estimators,numIterations,numAgents,lowerLim,upperLim):\n",
    "    agents,agentFIndex,agentStatus=agentsInitiation(arryX,numAgents,lowerLim,upperLim) #agents' datasets, 0-1 arrays, active' status\n",
    "    agentScores=agentClfscores(estimators,agents,arrY) # list of agents' scores\n",
    "    niters=0\n",
    "    while niters<numIterations: # um of iterations that testing and diffusion will happen\n",
    "        print(\"Iter: \" + str(niters))\n",
    "        #Testing phase\n",
    "        for i in range(len(agents)):\n",
    "            rndmId=np.random.randint(len(agents),size=1)[0]\n",
    "            if agentScores[i]>agentScores[rndmId]: # if ith agents has better score than a random agent, then become 'active' or 'happy' \n",
    "                agentStatus[i]='active' \n",
    "                \n",
    "            else:                                  # else if ith agent has worse score than a random agent, become 'inactive' or 'unhappy'\n",
    "                agentStatus[i]='inactive'\n",
    "                \n",
    "        #Diffusion phase    \n",
    "        for i in range(len(agents)):\n",
    "# ========= if ith agent is 'unhappy' =========\n",
    "            if agentStatus[i]=='inactive': \n",
    "                rndmId2=np.random.randint(len(agents),size=1)[0]\n",
    "# ============= if random agent is 'happy' =============\n",
    "                if agentStatus[rndmId2]=='active': \n",
    "                    oneIds=np.where(agentFIndex[rndmId2]==1)[0] # find where are the random agent's 1s\n",
    "                    #print(oneIds)\n",
    "                    zeroIds=np.where(agentFIndex[rndmId2]==0)[0] # find where are the random agent's 0s\n",
    "                    rndmId3=np.random.randint(len(oneIds), size=1) # create n1 random number in range [0,numOf1s]\n",
    "                    rndmId4=np.random.randint(len(zeroIds), size=1) # create n0 random number in range [0,numOf0s]\n",
    "                    oneZeroId=oneIds[rndmId3] # choose a 1-feature at random (from the random agent's 1s)\n",
    "                    zeroOneId=zeroIds[rndmId4] # choose a 0-feature at random (from the random agent's 0s)\n",
    "                    agentFIndex[i]=agentFIndex[rndmId2].copy() # copy the random agent's 0-1 array\n",
    "                    agentFIndex[i][oneZeroId]=0 # change this specific 1-feature to 0 (evolution?)\n",
    "                    agentFIndex[i][zeroOneId]=1 # change this specific 0-feature to 1 (evolution?)\n",
    "                    fIndex2=np.where(agentFIndex[i]==1)[0] # find where are the ith agent's 1s\n",
    "                    agents[i]=X[:,fIndex2] # create new dataset for the ith agent\n",
    "                    agentScores[i]=score(estimators,agents[i],arrY) # compute new score \n",
    "# ============= else if random agent is 'unhappy' =============\n",
    "                else:            \n",
    "                    agentFIndex[i],agents[i]=agent(arryX,lowerLim,upperLim) # try again with different random combination\n",
    "                    agentScores[i]=score(estimators,agents[i],arrY) # compute new score  \n",
    "# ========= else if ith agent is 'happy' ========= \n",
    "            else:                           \n",
    "                rndmId5=np.random.randint(len(agents),size=1)[0]\n",
    "                # if random agent == ith agent\n",
    "                if agentStatus[rndmId5]=='active' and (agentFIndex[i]==agentFIndex[rndmId5]).all():\n",
    "                    agentStatus[i]='inactive' # make ith agent 'inactive' or 'unhappy' (escape local minimal)\n",
    "                    agentFIndex[i],agents[i]=agent(arryX,lowerLim,upperLim) # try again with different random combination\n",
    "                    agentScores[i]=score(estimators,agents[i],arrY)\n",
    "        niters+=1\n",
    "    return agents,agentFIndex,agentStatus,agentScores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p style=\"color:Green\"><font size=\"5\">Experiments</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red\"><font size=\"4\">1) Sonar Signals</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 111 patterns obtained by bouncing sonar signals off a metal cylinder at various angles and under various conditions. \n",
    "It contains 97 patterns obtained from rocks under similar conditions. \n",
    "The transmitted sonar signal is a frequency-modulated chirp, rising in frequency. \n",
    "The data set contains signals obtained from a variety of different aspect angles, spanning 90 degrees for the cylinder and 180 degrees for the rock. \n",
    "\n",
    "More info on the dataset can be found <a href=\"https://www.openml.org/d/40\">here</a>.</font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./Sonar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape #the dataset has 60 features and one class column\n",
    "rows = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V52</th>\n",
       "      <th>V53</th>\n",
       "      <th>V54</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1      V2      V3      V4      V5      V6      V7      V8      V9  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "      V10  ...     V52     V53     V54     V55     V56     V57     V58  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "      V59     V60  Class  \n",
       "0  0.0090  0.0032      1  \n",
       "1  0.0052  0.0044      1  \n",
       "2  0.0095  0.0078      1  \n",
       "3  0.0040  0.0117      1  \n",
       "4  0.0107  0.0094      1  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    111\n",
       "1     97\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts() #the dataset has 111 class 0 instances and 97 class 1 instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True) #deleting any rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any().isnull().any() #confirming there are no missing values in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X and y set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(df[list(df.columns[:-1])])\n",
    "\n",
    "y=df['Class']\n",
    "\n",
    "original_cols = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: :0.035976409912109375 seconds\n",
      "Losgistic Regression Score: 0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "logReg.fit(X_train,y_train) #fitting Logistic Regression on Original Dataset\n",
    "\n",
    "end = time.time()\n",
    "print('Time elapsed: :' + str(end - start) + ' seconds')\n",
    "\n",
    "logReg_score=logReg.score(X_test,y_test) #Test score\n",
    "print('Losgistic Regression Score: ' + str(logReg_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: :0.14693069458007812 seconds\n",
      "Random Forest Score: 0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "rfc.fit(X_train,y_train) #fitting Random Forest to the original dataset\n",
    "\n",
    "end = time.time()\n",
    "print('Time elapsed: :' + str(end - start) + ' seconds')\n",
    "\n",
    "rfc_score=rfc.score(X_test,y_test)\n",
    "print('Random Forest Score: ' + str(rfc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: :0.006985902786254883 seconds\n",
      "Decision Tree Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "decClf.fit(X_train,y_train) #fitting decision tree classifer to the original dataset\n",
    "\n",
    "end = time.time()\n",
    "print('Time elapsed: :' + str(end - start) + ' seconds')\n",
    "\n",
    "decClf_score=decClf.score(X_test,y_test)\n",
    "print('Decision Tree Score: ' + str(decClf_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try to run SDSFS algorithm to check if it can improve the accuracy of the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Iter: 1\n",
      "Iter: 2\n",
      "Iter: 3\n",
      "Iter: 4\n",
      "Iter: 5\n",
      "Iter: 6\n",
      "Iter: 7\n",
      "Iter: 8\n",
      "Iter: 9\n",
      "Iter: 10\n",
      "Iter: 11\n",
      "Iter: 12\n",
      "Iter: 13\n",
      "Iter: 14\n",
      "Iter: 15\n",
      "Iter: 16\n",
      "Iter: 17\n",
      "Iter: 18\n",
      "Iter: 19\n",
      "32.56635761260986\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "agents,agentFIndex,agentStatus,agentScores=SDSFS(X,y,estimators,20,15,2,60)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8653846153846153"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(agentScores) #one of the agents achieved an accuracy of 86.5 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = np.argmax(np.array(agentScores)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "cols = agents[best].shape[1] \n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train the models on this agent instead of original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(agents[best],y, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "logReg_score2=logReg.score(X_test,y_test)\n",
    "print(logReg_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8846153846153846\n"
     ]
    }
   ],
   "source": [
    "rfc_score2=rfc.score(X_test,y_test) \n",
    "print(rfc_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, min_samples_split=4)"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decClf.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "decClf_score2=decClf.score(X_test,y_test) \n",
    "print(decClf_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result=pd.DataFrame([[logReg_score,rfc_score,decClf_score],\n",
    "                           [logReg_score2,rfc_score2,decClf_score2]],\n",
    "                          columns=['Logistic Regression','Random Forest','Decision Tree'], \n",
    "                          index=['original dataset ' + str(rows) + ' rows, ' + str(original_cols) + ' cols',\n",
    "                                 'SDSFS subset ' + str(rows) + ' rows, ' + str(cols) + ' cols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Decision Tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original dataset 208 rows, 60 cols</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDSFS subset 208 rows, 36 cols</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Logistic Regression  Random Forest  \\\n",
       "original dataset 208 rows, 60 cols             0.769231       0.846154   \n",
       "SDSFS subset 208 rows, 36 cols                 0.846154       0.884615   \n",
       "\n",
       "                                    Decision Tree  \n",
       "original dataset 208 rows, 60 cols       0.750000  \n",
       "SDSFS subset 208 rows, 36 cols           0.769231  "
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy improved for all the models with the subset obtained from SDSFS algorithm. I'm still trying to improve the algorithm to get more consistent and reliable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- We don't need more experiments here ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X and y set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = 180\n",
    "start = 50\n",
    "\n",
    "X=np.array(df[list(df.columns[:-1])][start:end]) \n",
    "\n",
    "y=df['Class'][start:end]\n",
    "\n",
    "original_cols = X.shape[1]\n",
    "\n",
    "cols=end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 60)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.01 seconds\n",
      "Losgistic Regression Score: 0.9393939393939394\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "logReg.fit(X_train,y_train) #fitting Logistic Regression on Original Dataset\n",
    "\n",
    "end = time.time()\n",
    "print('Time elapsed: ' + str(round(end - start,2)) + ' seconds')\n",
    "\n",
    "logReg_score3=logReg.score(X_test,y_test) #Test score\n",
    "print('Losgistic Regression Score: ' + str(logReg_score3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.14090204238891602 seconds\n",
      "Random Forest Score: 0.9393939393939394\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "rfc.fit(X_train,y_train) #fitting Random Forest to the original dataset\n",
    "\n",
    "end = time.time()\n",
    "print('Time elapsed: ' + str(end - start) + ' seconds')\n",
    "\n",
    "rfc_score3=rfc.score(X_test,y_test)\n",
    "print('Random Forest Score: ' + str(rfc_score3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.004979848861694336 seconds\n",
      "Decision Tree Score: 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "decClf.fit(X_train,y_train) #fitting decision tree classifer to the original dataset\n",
    "\n",
    "end = time.time()\n",
    "print('Time elapsed: ' + str(end - start) + ' seconds')\n",
    "\n",
    "decClf_score3=decClf.score(X_test,y_test)\n",
    "print('Decision Tree Score: ' + str(decClf_score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Iter: 1\n",
      "Iter: 2\n",
      "Iter: 3\n",
      "Iter: 4\n",
      "Iter: 5\n",
      "Iter: 6\n",
      "Iter: 7\n",
      "Iter: 8\n",
      "Iter: 9\n",
      "15.128660440444946\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "agents,agentFIndex,agentStatus,agentScores=SDSFS(X,y,estimators,10,15,10,20)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9292929292929294"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(agentScores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "best = np.argmax(np.array(agentScores)) \n",
    "\n",
    "cols = agents[best].shape[1] \n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(agents[best],y, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8484848484848485\n"
     ]
    }
   ],
   "source": [
    "logReg.fit(X_train,y_train)\n",
    "logReg_score4=logReg.score(X_test,y_test) \n",
    "print(logReg_score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9393939393939394\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(X_train,y_train)\n",
    "rfc_score4=rfc.score(X_test,y_test) \n",
    "print(rfc_score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9393939393939394\n"
     ]
    }
   ],
   "source": [
    "decClf.fit(X_train,y_train) \n",
    "decClf_score4=decClf.score(X_test,y_test) \n",
    "print(decClf_score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result=pd.DataFrame([[logReg_score3,rfc_score3,decClf_score3],\n",
    "                           [logReg_score4,rfc_score4,decClf_score4]],\n",
    "                          columns=['Logistic Regression','Random Forest','Decision Tree'], \n",
    "                          index=['original dataset ' + str(rows) + ' rows, ' + str(original_cols) + ' cols',\n",
    "                                 'SDSFS subset ' + str(rows) + ' rows, ' + str(cols) + ' cols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Decision Tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original dataset 150 rows, 60 cols</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDSFS subset 150 rows, 15 cols</th>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Logistic Regression  Random Forest  \\\n",
       "original dataset 150 rows, 60 cols             0.939394       0.939394   \n",
       "SDSFS subset 150 rows, 15 cols                 0.848485       0.939394   \n",
       "\n",
       "                                    Decision Tree  \n",
       "original dataset 150 rows, 60 cols       0.818182  \n",
       "SDSFS subset 150 rows, 15 cols           0.939394  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
